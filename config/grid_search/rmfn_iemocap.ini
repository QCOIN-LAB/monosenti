[COMMON]

datasets_dir = D:/qiuchi/data/multimodal/
data_dir = cmumosei_textual_avg
mode = run_grid_search
dataset_name = iemocap
dataset_type = multimodal
features = textual,visual,acoustic
wordvec_path = ../glove/glove.840B.300d.txt
label = emotion
dialogue_format = False

max_seq_len = 50
embedding_enabled = True
embedding_trainable = False

load_data_from_pickle = True
pickle_dir_path = D:/qiuchi/data/multimodal/cmumosi_cmumosei_iemocap/

case_study = False
model_prediction = True
true_labels = True
per_sample_analysis = True

seed =  123
grid_parameters_file = rmfn.ini
search_times = 50

network_type = rmfn
hidden_dims = 128,48,64
steps = 5
hlt_memory_init_cell_dim = 32
hlt_memory_init_dropout_rate = 0.3
compression_cell_dim = 64
compressed_dim = 32
compression_dropout_rate = 0.3
output_cell_dim = 64
output_dropout_rate = 0.3


batch_size = 128
epochs = 40
lr = 0.003
clip = 0.8
patience = 20
